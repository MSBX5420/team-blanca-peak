{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yellow_tripdata_2019-01.csv MapPartitionsRDD[1] at textFile at <unknown>:0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile(\"s3://msbx5420-2020/team-blanca-peak/yellow_tripdata_2019-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID,tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count,trip_distance,RatecodeID,store_and_fwd_flag,PULocationID,DOLocationID,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount,congestion_surcharge',\n",
       " '1,1/1/2019 0:46,1/1/2019 0:53,1,1.5,1,N,151,239,1,7,0.5,0.5,1.65,0,0.3,9.95,',\n",
       " '1,1/1/2019 0:59,1/1/2019 1:18,1,2.6,1,N,239,246,1,14,0.5,0.5,1,0,0.3,16.3,',\n",
       " '2,12/21/2018 13:48,12/21/2018 13:52,3,0,1,N,236,236,1,4.5,0.5,0.5,0,0,0.3,5.8,',\n",
       " '2,11/28/2018 15:52,11/28/2018 15:55,5,0,1,N,193,193,2,3.5,0.5,0.5,0,0,0.3,7.55,',\n",
       " '2,11/28/2018 15:56,11/28/2018 15:58,5,0,2,N,193,193,2,52,0,0.5,0,0,0.3,55.55,',\n",
       " '2,11/28/2018 16:25,11/28/2018 16:28,5,0,1,N,193,193,2,3.5,0.5,0.5,0,5.76,0.3,13.31,',\n",
       " '2,11/28/2018 16:29,11/28/2018 16:33,5,0,2,N,193,193,2,52,0,0.5,0,0,0.3,55.55,',\n",
       " '1,1/1/2019 0:21,1/1/2019 0:28,1,1.3,1,N,163,229,1,6.5,0.5,0.5,1.25,0,0.3,9.05,',\n",
       " '1,1/1/2019 0:32,1/1/2019 0:45,1,3.7,1,N,229,7,1,13.5,0.5,0.5,3.7,0,0.3,18.5,']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_write = rdd.\\\n",
    "    map(lambda x: x.split(\",\")).toDF()\n",
    "df_write.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>extra</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>DOLocationID</td>\n",
       "      <td>PULocationID</td>\n",
       "      <td>RatecodeID</td>\n",
       "      <td>VendorID</td>\n",
       "      <td>congestion_surcharge</td>\n",
       "      <td>extra</td>\n",
       "      <td>fare_amount</td>\n",
       "      <td>improvement_surcharge</td>\n",
       "      <td>mta_tax</td>\n",
       "      <td>passenger_count</td>\n",
       "      <td>payment_type</td>\n",
       "      <td>store_and_fwd_flag</td>\n",
       "      <td>tip_amount</td>\n",
       "      <td>tolls_amount</td>\n",
       "      <td>total_amount</td>\n",
       "      <td>tpep_dropoff_datetime</td>\n",
       "      <td>tpep_pickup_datetime</td>\n",
       "      <td>trip_distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>239</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0</td>\n",
       "      <td>9.95</td>\n",
       "      <td>1/1/2019 0:53</td>\n",
       "      <td>1/1/2019 0:46</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>246</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td>14</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>1/1/2019 1:18</td>\n",
       "      <td>1/1/2019 0:59</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>12/21/2018 13:52</td>\n",
       "      <td>12/21/2018 13:48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.55</td>\n",
       "      <td>11/28/2018 15:55</td>\n",
       "      <td>11/28/2018 15:52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DOLocationID  PULocationID  RatecodeID  VendorID  congestion_surcharge  \\\n",
       "0  DOLocationID  PULocationID  RatecodeID  VendorID  congestion_surcharge   \n",
       "1           239           151           1         1                         \n",
       "2           246           239           1         1                         \n",
       "3           236           236           1         2                         \n",
       "4           193           193           1         2                         \n",
       "\n",
       "   extra  fare_amount  improvement_surcharge  mta_tax  passenger_count  \\\n",
       "0  extra  fare_amount  improvement_surcharge  mta_tax  passenger_count   \n",
       "1    0.5            7                    0.3      0.5                1   \n",
       "2    0.5           14                    0.3      0.5                1   \n",
       "3    0.5          4.5                    0.3      0.5                3   \n",
       "4    0.5          3.5                    0.3      0.5                5   \n",
       "\n",
       "   payment_type  store_and_fwd_flag  tip_amount  tolls_amount  total_amount  \\\n",
       "0  payment_type  store_and_fwd_flag  tip_amount  tolls_amount  total_amount   \n",
       "1             1                   N        1.65             0          9.95   \n",
       "2             1                   N           1             0          16.3   \n",
       "3             1                   N           0             0           5.8   \n",
       "4             2                   N           0             0          7.55   \n",
       "\n",
       "   tpep_dropoff_datetime  tpep_pickup_datetime  trip_distance  \n",
       "0  tpep_dropoff_datetime  tpep_pickup_datetime  trip_distance  \n",
       "1          1/1/2019 0:53         1/1/2019 0:46            1.5  \n",
       "2          1/1/2019 1:18         1/1/2019 0:59            2.6  \n",
       "3       12/21/2018 13:52      12/21/2018 13:48              0  \n",
       "4       11/28/2018 15:55      11/28/2018 15:52              0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Enable Arrow-based columnar data transfers\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "\n",
    "# Convert the Spark DataFrame back to a pandas DataFrame using Arrow\n",
    "result_pdf = df_new.select(\"*\").toPandas()\n",
    "result_pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------+--------+--------------------+-----+-----------+---------------------+-------+---------------+------------+------------------+----------+------------+------------+---------------------+--------------------+-------------+\n",
      "|DOLocationID|PULocationID|RatecodeID|VendorID|congestion_surcharge|extra|fare_amount|improvement_surcharge|mta_tax|passenger_count|payment_type|store_and_fwd_flag|tip_amount|tolls_amount|total_amount|tpep_dropoff_datetime|tpep_pickup_datetime|trip_distance|\n",
      "+------------+------------+----------+--------+--------------------+-----+-----------+---------------------+-------+---------------+------------+------------------+----------+------------+------------+---------------------+--------------------+-------------+\n",
      "|DOLocationID|PULocationID|RatecodeID|VendorID|congestion_surcharge|extra|fare_amount| improvement_surch...|mta_tax|passenger_count|payment_type|store_and_fwd_flag|tip_amount|tolls_amount|total_amount| tpep_dropoff_date...|tpep_pickup_datetime|trip_distance|\n",
      "|         239|         151|         1|       1|                    |  0.5|          7|                  0.3|    0.5|              1|           1|                 N|      1.65|           0|        9.95|        1/1/2019 0:53|       1/1/2019 0:46|          1.5|\n",
      "|         246|         239|         1|       1|                    |  0.5|         14|                  0.3|    0.5|              1|           1|                 N|         1|           0|        16.3|        1/1/2019 1:18|       1/1/2019 0:59|          2.6|\n",
      "|         236|         236|         1|       2|                    |  0.5|        4.5|                  0.3|    0.5|              3|           1|                 N|         0|           0|         5.8|     12/21/2018 13:52|    12/21/2018 13:48|            0|\n",
      "|         193|         193|         1|       2|                    |  0.5|        3.5|                  0.3|    0.5|              5|           2|                 N|         0|           0|        7.55|     11/28/2018 15:55|    11/28/2018 15:52|            0|\n",
      "+------------+------------+----------+--------+--------------------+-----+-----------+---------------------+-------+---------------+------------+------------------+----------+------------+------------+---------------------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Register the people df as a table\n",
    "df.registerTempTable(\"taxi\")\n",
    "#Perform SQL Query\n",
    "taxi = spark.sql(\"SELECT * FROM taxi\")\n",
    "taxi.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi = taxi.na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DOLocationID', 'string'),\n",
       " ('PULocationID', 'string'),\n",
       " ('RatecodeID', 'string'),\n",
       " ('VendorID', 'string'),\n",
       " ('congestion_surcharge', 'string'),\n",
       " ('extra', 'string'),\n",
       " ('fare_amount', 'string'),\n",
       " ('improvement_surcharge', 'string'),\n",
       " ('mta_tax', 'string'),\n",
       " ('passenger_count', 'string'),\n",
       " ('payment_type', 'string'),\n",
       " ('store_and_fwd_flag', 'string'),\n",
       " ('tip_amount', 'string'),\n",
       " ('tolls_amount', 'string'),\n",
       " ('total_amount', 'string'),\n",
       " ('tpep_dropoff_datetime', 'string'),\n",
       " ('tpep_pickup_datetime', 'string'),\n",
       " ('trip_distance', 'string')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048576"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+--------+-----+-----------+---------------+------------+------------+------------+-------------+----------+---+\n",
      "|DOLocationID|PULocationID|VendorID|extra|fare_amount|passenger_count|payment_type|tolls_amount|total_amount|trip_distance|tip_amount|tip|\n",
      "+------------+------------+--------+-----+-----------+---------------+------------+------------+------------+-------------+----------+---+\n",
      "|DOLocationID|PULocationID|VendorID|extra|fare_amount|passenger_count|payment_type|tolls_amount|total_amount|trip_distance|tip_amount|tip|\n",
      "|         239|         151|       1|  0.5|          7|              1|           1|           0|        9.95|          1.5|      1.65|tip|\n",
      "|         246|         239|       1|  0.5|         14|              1|           1|           0|        16.3|          2.6|         1|tip|\n",
      "|         236|         236|       2|  0.5|        4.5|              3|           1|           0|         5.8|            0|         0|tip|\n",
      "|         193|         193|       2|  0.5|        3.5|              5|           2|           0|        7.55|            0|         0|tip|\n",
      "+------------+------------+--------+-----+-----------+---------------+------------+------------+------------+-------------+----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi = spark.sql(\"SELECT DOLocationID,PULocationID,VendorID,extra,fare_amount,\\\n",
    "                 passenger_count,payment_type,tolls_amount,\\\n",
    "                 total_amount,trip_distance,tip_amount,'tip' FROM taxi\")\n",
    "taxi.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+--------+-----+-----------+---------------+------------+------------+------------+-------------+---+\n",
      "|DOLocationID|PULocationID|VendorID|extra|fare_amount|passenger_count|payment_type|tolls_amount|total_amount|trip_distance|tip|\n",
      "+------------+------------+--------+-----+-----------+---------------+------------+------------+------------+-------------+---+\n",
      "|DOLocationID|PULocationID|VendorID|extra|fare_amount|passenger_count|payment_type|tolls_amount|total_amount|trip_distance|  0|\n",
      "|         239|         151|       1|  0.5|          7|              1|           1|           0|        9.95|          1.5|  1|\n",
      "|         246|         239|       1|  0.5|         14|              1|           1|           0|        16.3|          2.6|  1|\n",
      "|         236|         236|       2|  0.5|        4.5|              3|           1|           0|         5.8|            0|  0|\n",
      "|         193|         193|       2|  0.5|        3.5|              5|           2|           0|        7.55|            0|  0|\n",
      "+------------+------------+--------+-----+-----------+---------------+------------+------------+------------+-------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as sf\n",
    "taxi = taxi.withColumn('tip', sf.when(sf.col('tip_amount') > 0, 1).otherwise(0))\n",
    "taxi = taxi.drop('tip_amount')\n",
    "taxi.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taxi.na.drop(subset=taxi.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DOLocationID',\n",
       " 'PULocationID',\n",
       " 'VendorID',\n",
       " 'extra',\n",
       " 'fare_amount',\n",
       " 'passenger_count',\n",
       " 'payment_type',\n",
       " 'tolls_amount',\n",
       " 'total_amount',\n",
       " 'trip_distance',\n",
       " 'tip']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql.functions import col\n",
    "#taxi = taxi.select(*(col(c).cast(\"float\").alias(c) for c in taxi.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#taxi.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = ['DOLocationID', 'PULocationID', 'VendorID', \n",
    " #                                              'extra', 'fare_amount', 'passenger_count', 'payment_type', 'tolls_amount', \n",
    "  #                                             'total_amount', 'trip_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taxi.fillna(0, subset=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taxi.fillna(0, subset=['tip_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DOLocationID',\n",
       " 'PULocationID',\n",
       " 'VendorID',\n",
       " 'extra',\n",
       " 'fare_amount',\n",
       " 'passenger_count',\n",
       " 'payment_type',\n",
       " 'tolls_amount',\n",
       " 'total_amount',\n",
       " 'trip_distance']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "categorical_columns = taxi.columns[:-1]\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringindexer_stages = [StringIndexer(inputCol=c, outputCol='stringindexed_' + c) for c in categorical_columns]\n",
    "# encode label column and add it to stringindexer stages\n",
    "stringindexer_stages += [StringIndexer(inputCol='tip', outputCol='label')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder_stages = [OneHotEncoder(inputCol='stringindexed_' + c, outputCol='onehot_'+c) for c in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['onehot_' + c for c in categorical_columns]\n",
    "vectorassembler_stage = VectorAssembler(inputCols=feature_columns, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stages = stringindexer_stages + onehotencoder_stages + [vectorassembler_stage]\n",
    "pipeline = Pipeline(stages=all_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = feature_columns + ['features', 'label']\n",
    "taxi_df = pipeline_model.transform(taxi).select(final_columns)\n",
    "#taxi_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = taxi_df.randomSplit([0.8, 0.2], seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(featuresCol='features', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "param_grid = ParamGridBuilder().\\\n",
    "    addGrid(random_forest.maxDepth, [2, 3, 4]).\\\n",
    "    addGrid(random_forest.minInfoGain, [0.0, 0.1, 0.2, 0.3]).\\\n",
    "    build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "crossvalidation = CrossValidator(estimator=random_forest, estimatorParamMaps=param_grid, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossvalidation_mod = crossvalidation.fit(taxi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+---------------+--------------+------------------+----------------------+-------------------+-------------------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|onehot_DOLocationID|onehot_PULocationID|onehot_VendorID|  onehot_extra|onehot_fare_amount|onehot_passenger_count|onehot_payment_type|onehot_tolls_amount|onehot_total_amount|onehot_trip_distance|            features|label|       rawPrediction|         probability|prediction|\n",
      "+-------------------+-------------------+---------------+--------------+------------------+----------------------+-------------------+-------------------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|    (260,[0],[1.0])|    (253,[0],[1.0])|  (3,[0],[1.0])|(18,[0],[1.0])|  (3035,[0],[1.0])|        (10,[0],[1.0])|      (4,[1],[1.0])|    (347,[0],[1.0])|   (6965,[5],[1.0])|   (3237,[77],[1.0])|(14132,[0,260,513...|  1.0|[8.39496193125127...|[0.41974809656256...|       1.0|\n",
      "|    (260,[0],[1.0])|    (253,[0],[1.0])|  (3,[0],[1.0])|(18,[0],[1.0])|  (3035,[1],[1.0])|        (10,[1],[1.0])|      (4,[1],[1.0])|    (347,[0],[1.0])|   (6965,[0],[1.0])|  (3237,[100],[1.0])|(14132,[0,260,513...|  1.0|[8.88123551998036...|[0.44406177599901...|       1.0|\n",
      "|    (260,[0],[1.0])|    (253,[0],[1.0])|  (3,[0],[1.0])|(18,[0],[1.0])|  (3035,[2],[1.0])|        (10,[0],[1.0])|      (4,[0],[1.0])|    (347,[0],[1.0])|  (6965,[14],[1.0])|    (3237,[7],[1.0])|(14132,[0,260,513...|  0.0|[13.4796966038858...|[0.67398483019429...|       0.0|\n",
      "|    (260,[0],[1.0])|    (253,[0],[1.0])|  (3,[0],[1.0])|(18,[0],[1.0])|  (3035,[4],[1.0])|        (10,[0],[1.0])|      (4,[0],[1.0])|    (347,[0],[1.0])|  (6965,[17],[1.0])|  (3237,[126],[1.0])|(14132,[0,260,513...|  0.0|[13.3542180773504...|[0.66771090386752...|       0.0|\n",
      "|    (260,[0],[1.0])|    (253,[0],[1.0])|  (3,[0],[1.0])|(18,[0],[1.0])|  (3035,[5],[1.0])|        (10,[0],[1.0])|      (4,[0],[1.0])|    (347,[0],[1.0])|  (6965,[79],[1.0])|  (3237,[113],[1.0])|(14132,[0,260,513...|  0.0|[13.3542180773504...|[0.66771090386752...|       0.0|\n",
      "+-------------------+-------------------+---------------+--------------+------------------+----------------------+-------------------+-------------------+-------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test = crossvalidation_mod.transform(test)\n",
    "pred_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {Row(label=1.0, prediction=1.0): 71065,\n",
       "             Row(label=0.0, prediction=0.0): 123914,\n",
       "             Row(label=1.0, prediction=0.0): 14713,\n",
       "             Row(label=0.0, prediction=1.0): 11})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pred_test = pred_test.select('label', 'prediction')\n",
    "label_pred_test.rdd.zipWithIndex().countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.949336736230964\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy : ', evaluator.setMetricName('areaUnderROC').evaluate(pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision :  0.9582574636676763\n"
     ]
    }
   ],
   "source": [
    "#print('Precision : ', evaluator.setMetricName('areaUnderPR').evaluate(pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision : ', evaluator.setMetricName('precision').evaluate(pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FeatureImportanceSelector import ExtractFeatureImp, FeatureImpSelector\n",
    "\n",
    "bestPipeline = crossvalidation_mod.bestModel\n",
    "bestModel = bestPipeline.stages[1]\n",
    "\n",
    "importances = bestModel.featureImportances\n",
    "\n",
    "x_values = list(range(len(importances)))\n",
    "\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "plt.xticks(x_values, feature_list, rotation=40)\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Feature')\n",
    "plt.title('Feature Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "#evaluator = MulticlassClassificationEvaluator(metricName=\"precision\")\n",
    "#print(\"Precision:\" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
