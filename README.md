# Objective
This objective of this project is to work on big data in the AWS environment. Ingest dataset to Hdfs or S3 and save as Parquet format. Basic statistics, data analysis, visualization and machine learning using the ingested dataset.

# Team Members
Chaerin Lee <br/>
Dean Duke <br/>
Ethan Goldbeck <br/>
Matthew Kuchar <br/>
Soumya Panda <br/>

# Technologies/Concepts Used
AWS S3 - To Ingest and Read Data <br/>
Python - PySpark <br/>
Data Analysis and Visualization <br/>
PySpark Machine Learning <br/>

# Dataset
https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page
